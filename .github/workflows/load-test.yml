name: Teste de Carga
on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  workflow_dispatch:
    inputs:
      env:
        description: "Ambiente alvo"
        required: true
        default: "staging"
        type: choice
        options:
          - staging
          - production

env:
  API_URL: ${{ inputs.env == 'production' && 'https://api.marketoflow.com' || 'https://staging.marketoflow.com' }}
  API_TOKEN: ${{ secrets.API_TOKEN }}
  K6_CLOUD_TOKEN: ${{ secrets.K6_CLOUD_TOKEN }}

jobs:
  performance-test:
    name: Teste de Carga - ${{ inputs.env || 'staging' }}
    runs-on: ubuntu-latest
    container: grafana/k6

    steps:
      - name: Baixar código
        uses: actions/checkout@v4

      - name: Validar ambiente
        run: |
          if [ -z "$API_TOKEN" ]; then
            echo "::error::Token API não configurado!"
            exit 1
          fi
          echo "✔ Ambiente configurado: $API_URL"

      - name: Instalar jq
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Executar teste
        id: teste-k6
        run: |
          k6 run tests/performance/loadTest.js \
            --env API_URL="$API_URL" \
            --env API_TOKEN="$API_TOKEN" \
            --vus ${{ inputs.env == 'production' && '200' || '100' }} \
            --duration ${{ inputs.env == 'production' && '10m' || '5m' }} \
            ${{ env.K6_CLOUD_TOKEN && '--out cloud' || '' }} \
            --out json=test_results.json \
            --summary-export=summary.json

      - name: Enviar resultados
        uses: actions/upload-artifact@v4
        with:
          name: resultados-${{ github.run_id }}-${{ inputs.env || 'staging' }}
          path: |
            test_results.json
            summary.json

      - name: Verificar métricas
        id: verificar-metricas
        run: |
          echo "Relatório:"
          jq '.metrics | {
            taxa_sucesso: .checks.values.pass,
            taxa_falha: .http_req_failed.values.rate,
            duracao_media: .http_req_duration.values.avg,
            p95_duracao: .http_req_duration.values."p(95)"
          }' summary.json
          
          # Converter métricas para variáveis
          TAXA_FALHA=$(jq -r '.metrics.http_req_failed.values.rate' summary.json)
          DURACAO_P95=$(jq -r '.metrics.http_req_duration.values."p(95)"' summary.json)
          
          # Definir limites
          LIMITE_FALHA=0.01   # 1%
          LIMITE_DURACAO=500  # 500ms
          
          # Verificar limites
          if (( $(echo "$TAXA_FALHA > $LIMITE_FALHA" | bc -l) )) || 
             (( $(echo "$DURACAO_P95 > $LIMITE_DURACAO" | bc -l) )); then
            echo "::warning::Algumas métricas não atingiram o esperado"
            echo "METRICAS_OK=false" >> $GITHUB_OUTPUT
          else
            echo "METRICAS_OK=true" >> $GITHUB_OUTPUT
          fi

      - name: Falhar se métricas não atendem
        if: steps.verificar-metricas.outputs.METRICAS_OK == 'false'
        run: |
          echo "::error::O teste não atingiu os requisitos de performance"
          exit 1